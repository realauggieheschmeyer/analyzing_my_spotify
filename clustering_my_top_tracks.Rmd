---
title: "Clustering My Top Tracks"
author: "Auggie Heschmeyer"
date: "5/25/2020"
output: html_document
theme: sandstone
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 8)

library(spotifyr)
library(knitr)

Sys.setenv(SPOTIFY_CLIENT_ID = "a905fab479a848579b4a190f33e57aa6")
Sys.setenv(SPOTIFY_CLIENT_SECRET = "02c30b0b7def484b871779e6c0359704")

access_token <- get_spotify_access_token()
```

I recently discovered the [`spotifyr`](https://www.rcharlie.com/spotifyr/) package that allows you to access the Spotify API data within R. More importantly, it allows you the opportunity to download and analyze your own listening data. As a data nerd and an avid Spotify user, I thought it would make a fun exercise to see if there are any patterns within the music I listen to and if I can back up my self-described musical tastes ("alternative rock with a pop bent") with data.

In this post I'll take a look at my top *tracks* and their audio features to see how if I can find my own "genres." This analysis is part two of an an earlier analysis in which I clustered my top artists. Check that one out first as I went into slightly more detail about accessing my data as well as utilizing some text mining methodologies.

### Setting Up the API

If you followed along with my last post, you should have your Spotify credentials on-hand and be ready to get your access token. Otherwise, check out the [`spotifyr` website](https://www.rcharlie.com/spotifyr/) for instructions on how to get access to the Spotify API. Once you have your credentials, you can run the following lines of code to get your access token.

```{r eval=FALSE}
library(spotifyr)

Sys.setenv(SPOTIFY_CLIENT_ID = 'xxxxxxxxxxxxxxxxxxxxx')
Sys.setenv(SPOTIFY_CLIENT_SECRET = 'xxxxxxxxxxxxxxxxxxxxx')

access_token <- get_spotify_access_token()
```

### Getting My Top Tracks Data

Just like last time, we are going to use the `get_my_top_artists_or_tracks()` function. We're going to keep `limit` and `time_range` the same (`50` and `"medium_term"`) as we are interested in analyzing the same time period as we did last time. This time, however, we are going to switch our `type` argument from `"artist"` to `"tracks"`. Again, we're going to save the output of `get_my_top_artists_or_tracks()` as a tibble.

```{r}
library(tidyverse)

my_top_songs_tbl <- get_my_top_artists_or_tracks(
  type = "tracks",
  limit = 50,
  time_range = "medium_term"
) %>% 
  as_tibble()
```

Let's take a quick `glimpse()` at our data.

```{r}
my_top_songs_tbl %>% 
  glimpse()
```

We are provided with a lot of data about individual tracks, most of it revolving around the album details. One thing to notice about this data is that our `artists` information is stored as a nested list. This is because certain tracks have feature artists or are collaborations. Let's make our first processing step extracting those artist names and combining them in a logical way. We'll do that by defining our own function that unnests the `artists` column and concatenates the names using a `/`. 

```{r}
combine_artists <- function(df) {
  
  df %>% 
    unnest() %>% 
    pull(name) %>% 
    str_c(collapse = " / ")
  
}
```

Now we'll take our new function and use it to clean up our data. We're going to bring along the `popularity` variable as it proved valuable in clustering my top artists together last time. We're also going to rename the song-related variables so that we don't run into an error message when we unnest the similarly-named artist variables.

```{r}
my_top_songs_cleaned_tbl <- my_top_songs_tbl %>%
  mutate(my_ranking = row_number()) %>% 
  rename(
    song = name,
    song_id = id
  ) %>%
  mutate(artist = map_chr(artists, combine_artists)) %>%
  select(song_id, song, artist, popularity, my_ranking)

my_top_songs_cleaned_tbl %>% 
  slice(1:10) %>% 
  kable()
```

Nice and clean, right? If you remember the types of artists I listened to from my last post, the types of songs on this list shouldn't be much of a surprise. There is a fair mix of pop and alternative music with some heavier stuff thrown in for good measure. And no, that's not a typo; both the regular and acoustic versions of "Daphne Blue" are two of my most-played tracks. The song slaps ¯\\_(ツ)_/¯.

Let's take a quick look at the popularity of my top songs across all Spotify users.

```{r}
library(ggdark)

my_top_songs_cleaned_tbl %>% 
  mutate(
    plot_name = str_c(song, artist, sep = "\n"),
    plot_name = plot_name %>% as_factor() %>% fct_reorder(popularity)
  ) %>% 
  arrange(my_ranking) %>% 
  slice(1:10) %>% 
  ggplot(aes(x = popularity, y = plot_name)) +
  geom_col(fill = "#1DB954") +
  dark_theme_minimal() +
  labs(
    title = "My Top 10 Songs Over the Last Six Months",
    subtitle = "Ordered by Song's Popularity",
    x = "Popularity",
    y = "Song"
  )
```

I'm actually kind of shocked by the popularity of "Popular Monster" as it's a heavy song with heavy themes. I suppose it's a testament to the quality of the song.

### Getting Track Audio Features

One of the coolest features of the Spotify API is that you can access track audio features. Audio features act as a sort of DNA for each song on Spotify and measure aspects of the music such as their energy levels, how likely the song is to be a live recording, how happy the song and more traditional measure like key and tempo. You can learn more about The Echo Nest, Spotify's acquisition that enabled this technology, [in this article](https://techcrunch.com/2014/03/06/spotify-acquires-the-echo-nest/).

We are going to use the following chunk of code to download the audio features for each of my top tracks.

```{r}
my_top_songs_features_tbl <- my_top_songs_cleaned_tbl %>%
  mutate(audio_features = map(song_id, get_track_audio_features)) %>% 
  unnest(audio_features) %>%
  mutate(duration_m = duration_ms / 1000 / 60) %>% 
  select(-contains("id"), -uri, -track_href, -analysis_url, -type, -duration_ms)
```

I saved the song duration (`duration_m`) as I thought it might make an interesting variable to include in our clustering later.

Let's see how this data looks.

```{r}
my_top_songs_features_tbl %>% 
  glimpse()
```

As you can see, there is a lot of data here and most of it is on different scales. Let's plot some histograms to get a better sense of how this data is distributed.

```{r}
my_top_songs_features_tbl %>% 
  pivot_longer(cols = danceability:duration_m, names_to = "feature", values_to = "measure") %>% 
  ggplot(aes(x = measure)) +
  geom_histogram(fill = "#1DB954", bins = sqrt(50)) +
  dark_theme_minimal() +
  facet_wrap(~ feature, scales = "free")
```

What immediately jumps out to me is that `time_signature` has only a single value: 4/4. That means we can drop this variable when it comes time to start clustering as it won't add any information to the model.

After that, I notice that `valence` (a measure of the positivity of the track) and `danceability` are almost normally distributed with some skew towards the low and high ends, respectively. Diagnosing why my top songs seem to be negative songs that make you want to dance is an issue that I'm sure will make my future therapist very rich.

`Acousticness`, `liveness` and `instrumentalness` both feature large right skews indicating a preference for heavily produced, studio recordings with lots of singing. Loudness, however, features a left skew indicating that I like my heavily produced, studio recordings with lots of singing played **loud**.

You can read more about the definitions of these variables as well as seeing their population distributions in the [Spotify for Developers reference guide](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/).

Let's go ahead and normalize all of these audio features to make sure that none of them have undue weight in our clustering algorithm.

```{r}
library(recipes)

song_features_processed_tbl <- recipe(song + artist ~ ., data = my_top_songs_features_tbl) %>% 
  step_rm(time_signature, my_ranking, duration_m, popularity, instrumentalness, key) %>% 
  step_normalize(all_numeric()) %>%
  prep() %>% 
  juice()
```

### K-Means Clustering

Now that we have our data in a cluster-friendly format, let's define the clustering function we used in the last analysis. This function allowed us to utilize a k-means clustering algorithm in a tidy way.

```{r}
kmeans_mapper <- function(data, centers = 3) {
  
  data %>%
    kmeans(centers = centers, nstart = 100)
  
}
```

Just like last time, we're going to use the `glance()` function to extract relevant metrics from the algorithm and the `set.seed()` function to ensure reproducible.

```{r}
library(broom)

set.seed(123)
kmeans_songs_mapped_tbl <- tibble(centers = 1:15) %>% 
  mutate(k_means = centers %>% map(kmeans_mapper, data = song_features_processed_tbl %>% select(-song, -artist)),
         glance = k_means %>% map(glance))
```

Now, we'll extract the necessary information from each model to make a skree plot and see if there is an ideal number of clusters.

```{r}
kmeans_songs_mapped_tbl %>%
  unnest(glance) %>%
  select(centers, tot.withinss) %>%
  ggplot(aes(x = centers, y = tot.withinss)) +
  geom_point(color = "#1DB954", size = 4) +
  geom_line(color = "#1DB954") +
  dark_theme_minimal() +
  labs(title = "Skree plot")
```

There is no discernible "elbow" to this plot so any choice we make will be rather arbitrary. With that in mind, I'm going to pick six centers because I have a feeling that my taste in songs will have some variety to them and I want to allow the algorithm adequate bandwidth to capture that variety.

### Dimensionality Reduction

Just like last time, we're going to make use of the UMAP non-linear dimensionality reduction technique. We'll also bind our song and artist names onto these new, reduced variables.

```{r}
library(umap)

set.seed(123)
umap_songs_obj <- song_features_processed_tbl %>% 
  select(-song, -artist) %>% 
  umap()

umap_songs_results_tbl <- umap_songs_obj$layout %>% 
  as_tibble() %>%
  set_names(c("x", "y")) %>% 
  bind_cols(song_features_processed_tbl %>% 
              select(song, artist))

umap_songs_results_tbl %>% 
  head() %>% 
  kable()
```

All of that complex audio feature data has now been reduced to a concise and easily-to-visualize pair of features.

### Plotting the Track Clusters

Now that we've done the hard work of clustering the artists and reducing the number of variables we use to describe them, now comes the fun part: visualizing the clusters. We'll use the following chunks of code to pull the cluster information, use the `augment()` function to extract the clusters numbers and then join those cluster numbers to the UMAP-reduced variables.

```{r}
kmeans_songs_obj <- kmeans_songs_mapped_tbl %>% 
  pull(k_means) %>% 
  pluck(6)

kmeans_clusters_songs_tbl <- kmeans_songs_obj %>% 
  augment(song_features_processed_tbl) %>% 
  select(song, artist, .cluster)

umap_kmeans_results_songs_tbl <- umap_songs_results_tbl %>% 
  left_join(kmeans_clusters_songs_tbl,
            by = c("song", "artist"))

umap_kmeans_results_songs_tbl %>% 
  glimpse()
```

Before plotting, we're going to add a `label_text` variable so that we have some nice labeling on our finished plot. We're also going to use the `ggreepel` package to ensure that our labels are plotted in a readable way.

```{r}
library(ggrepel)

umap_kmeans_results_songs_tbl %>%
  mutate(
    label_text = str_glue("Song: {song}\nArtist: {artist}\nCluster: {.cluster}")
  ) %>% 
  ggplot(aes(x, y, color = .cluster)) +
  geom_point() +
  geom_label_repel(aes(label = label_text), 
                   size = 2, 
                   fill = "black") +
  dark_theme_minimal() +
  labs(
    title = "Grouping My Top Tracks By Audio Features",
    x = "",
    y = ""
  ) +
  theme(legend.position = "none")
```

It looks like six clusters wasn't too bad of a choice. Nice!

Cluster 1 is the smallest of the clusters with two songs and it's what I would call the "let's talk as fast as we can" genre; "Godzilla" has Eminem rapping some of the fastest lyrics he's ever done and "idontknow," while technically an instrumental track, features spoken word samples sped up to go really fast. This is a pretty fascinating grouping by the k-means algorithm.

Cluster 2 features a lot of happy, high-energy songs and a lot of The 1975 and The Band CAMINO. 

Cluster 3 features high-energy songs with some less-than-happy themes; Twenty One Pilots "Level of Concern" will probably be the most danceable song ever recorded about being stuck in quarantine.

Cluster 4 is what I would call "fast, loud and angry." This is where most of the metal tracks I've listened to make an appearance.

Cluster 5 is the mellow cluster and features the only classical recording to make my top tracks list. Before you think you might've discovered some culture buried deep within my music taste, know that Ramin Djawadi's "Wicked Games" is a cover of The Weeknd's "Wicked Games" that he recorded for Westworld. So, in actuality, I'm just as basic as I seem.

Finally, Cluster 6 feature songs that I would describe as "anthemic." They're the type of songs that you might not know all the words to, but you can't help but shouting along to the chorus.

Thanks for walking through this analysis with me. Check out the `spotifyr` package yourself and feel free to tag me on [Twitter](https://twitter.com/realauggiehesch) with what you find. I'd love to see. And please check back on my blog soon for more analyses.